import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import math


class Model(nn.Module):

    def __init__(self,args):
        super(Model, self).__init__()
        self.num_classes = args.get('num_classes',1000)
        self.conv1 = self.__conv(2, name='conv1', in_channels=3, out_channels=8, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)

        self.conv1_bn = self.__batch_normalization(2, 'conv1/bn', num_features=8, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_1_x1 = self.__conv(2, name='conv2_1/x1', in_channels=8, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_1_x2_bn = self.__batch_normalization(2, 'conv2_1/x2/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_1_x2 = self.__conv(2, name='conv2_1/x2', in_channels=16, out_channels=8, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_1_x3_bn = self.__batch_normalization(2, 'conv2_1/x3/bn', num_features=8, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_2_x1 = self.__conv(2, name='conv2_2/x1', in_channels=16, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_2_x2_bn = self.__batch_normalization(2, 'conv2_2/x2/bn', num_features=32, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_2_x2 = self.__conv(2, name='conv2_2/x2', in_channels=32, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_2_x3_bn = self.__batch_normalization(2, 'conv2_2/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_3_x1 = self.__conv(2, name='conv2_3/x1', in_channels=32, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_3_x2_bn = self.__batch_normalization(2, 'conv2_3/x2/bn', num_features=32, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_3_x2 = self.__conv(2, name='conv2_3/x2', in_channels=32, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_3_x3_bn = self.__batch_normalization(2, 'conv2_3/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_4_x1 = self.__conv(2, name='conv2_4/x1', in_channels=48, out_channels=48, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_4_x2_bn = self.__batch_normalization(2, 'conv2_4/x2/bn', num_features=48, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_4_x2 = self.__conv(2, name='conv2_4/x2', in_channels=48, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_4_x3_bn = self.__batch_normalization(2, 'conv2_4/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_5_x1 = self.__conv(2, name='conv2_5/x1', in_channels=64, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_5_x2_bn = self.__batch_normalization(2, 'conv2_5/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_5_x2 = self.__conv(2, name='conv2_5/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_5_x3_bn = self.__batch_normalization(2, 'conv2_5/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_6_x1 = self.__conv(2, name='conv2_6/x1', in_channels=80, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_6_x2_bn = self.__batch_normalization(2, 'conv2_6/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv2_6_x2 = self.__conv(2, name='conv2_6/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_6_x3_bn = self.__batch_normalization(2, 'conv2_6/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_1_x1 = self.__conv(2, name='conv3_1/x1', in_channels=96, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_1_x2_bn = self.__batch_normalization(2, 'conv3_1/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_1_x2 = self.__conv(2, name='conv3_1/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_1_x3_bn = self.__batch_normalization(2, 'conv3_1/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_2_x1 = self.__conv(2, name='conv3_2/x1', in_channels=112, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_2_x2_bn = self.__batch_normalization(2, 'conv3_2/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_2_x2 = self.__conv(2, name='conv3_2/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_2_x3_bn = self.__batch_normalization(2, 'conv3_2/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_3_x1 = self.__conv(2, name='conv3_3/x1', in_channels=128, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_3_x2_bn = self.__batch_normalization(2, 'conv3_3/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_3_x2 = self.__conv(2, name='conv3_3/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_3_x3_bn = self.__batch_normalization(2, 'conv3_3/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_4_x1 = self.__conv(2, name='conv3_4/x1', in_channels=144, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_4_x2_bn = self.__batch_normalization(2, 'conv3_4/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_4_x2 = self.__conv(2, name='conv3_4/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_4_x3_bn = self.__batch_normalization(2, 'conv3_4/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_5_x1 = self.__conv(2, name='conv3_5/x1', in_channels=160, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_5_x2_bn = self.__batch_normalization(2, 'conv3_5/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_5_x2 = self.__conv(2, name='conv3_5/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_5_x3_bn = self.__batch_normalization(2, 'conv3_5/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_6_x1 = self.__conv(2, name='conv3_6/x1', in_channels=176, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_6_x2_bn = self.__batch_normalization(2, 'conv3_6/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_6_x2 = self.__conv(2, name='conv3_6/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_6_x3_bn = self.__batch_normalization(2, 'conv3_6/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_7_x1 = self.__conv(2, name='conv3_7/x1', in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_7_x2_bn = self.__batch_normalization(2, 'conv3_7/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_7_x2 = self.__conv(2, name='conv3_7/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_7_x3_bn = self.__batch_normalization(2, 'conv3_7/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_8_x1 = self.__conv(2, name='conv3_8/x1', in_channels=208, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_8_x2_bn = self.__batch_normalization(2, 'conv3_8/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_8_x2 = self.__conv(2, name='conv3_8/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_8_x3_bn = self.__batch_normalization(2, 'conv3_8/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv3_blk = self.__conv(2, name='conv3_blk', in_channels=224, out_channels=96, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_blk_bn = self.__batch_normalization(2, 'conv3_blk/bn', num_features=96, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_1_x1 = self.__conv(2, name='conv4_1/x1', in_channels=96, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_1_x2_bn = self.__batch_normalization(2, 'conv4_1/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_1_x2 = self.__conv(2, name='conv4_1/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_1_x3_bn = self.__batch_normalization(2, 'conv4_1/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_2_x1 = self.__conv(2, name='conv4_2/x1', in_channels=112, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_2_x2_bn = self.__batch_normalization(2, 'conv4_2/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_2_x2 = self.__conv(2, name='conv4_2/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_2_x3_bn = self.__batch_normalization(2, 'conv4_2/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_3_x1 = self.__conv(2, name='conv4_3/x1', in_channels=128, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_3_x2_bn = self.__batch_normalization(2, 'conv4_3/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_3_x2 = self.__conv(2, name='conv4_3/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_3_x3_bn = self.__batch_normalization(2, 'conv4_3/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_4_x1 = self.__conv(2, name='conv4_4/x1', in_channels=144, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_4_x2_bn = self.__batch_normalization(2, 'conv4_4/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_4_x2 = self.__conv(2, name='conv4_4/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_4_x3_bn = self.__batch_normalization(2, 'conv4_4/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_5_x1 = self.__conv(2, name='conv4_5/x1', in_channels=160, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_5_x2_bn = self.__batch_normalization(2, 'conv4_5/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_5_x2 = self.__conv(2, name='conv4_5/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_5_x3_bn = self.__batch_normalization(2, 'conv4_5/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_6_x1 = self.__conv(2, name='conv4_6/x1', in_channels=176, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_6_x2_bn = self.__batch_normalization(2, 'conv4_6/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_6_x2 = self.__conv(2, name='conv4_6/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_6_x3_bn = self.__batch_normalization(2, 'conv4_6/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_7_x1 = self.__conv(2, name='conv4_7/x1', in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_7_x2_bn = self.__batch_normalization(2, 'conv4_7/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_7_x2 = self.__conv(2, name='conv4_7/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_7_x3_bn = self.__batch_normalization(2, 'conv4_7/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_8_x1 = self.__conv(2, name='conv4_8/x1', in_channels=208, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_8_x2_bn = self.__batch_normalization(2, 'conv4_8/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_8_x2 = self.__conv(2, name='conv4_8/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_8_x3_bn = self.__batch_normalization(2, 'conv4_8/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv4_blk = self.__conv(2, name='conv4_blk', in_channels=224, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_blk_bn = self.__batch_normalization(2, 'conv4_blk/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_1_x1 = self.__conv(2, name='conv5_1/x1', in_channels=128, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_1_x2_bn = self.__batch_normalization(2, 'conv5_1/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_1_x2 = self.__conv(2, name='conv5_1/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_1_x3_bn = self.__batch_normalization(2, 'conv5_1/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_2_x1 = self.__conv(2, name='conv5_2/x1', in_channels=144, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_2_x2_bn = self.__batch_normalization(2, 'conv5_2/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_2_x2 = self.__conv(2, name='conv5_2/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_2_x3_bn = self.__batch_normalization(2, 'conv5_2/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_3_x1 = self.__conv(2, name='conv5_3/x1', in_channels=160, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_3_x2_bn = self.__batch_normalization(2, 'conv5_3/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_3_x2 = self.__conv(2, name='conv5_3/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_3_x3_bn = self.__batch_normalization(2, 'conv5_3/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_4_x1 = self.__conv(2, name='conv5_4/x1', in_channels=176, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_4_x2_bn = self.__batch_normalization(2, 'conv5_4/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_4_x2 = self.__conv(2, name='conv5_4/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_4_x3_bn = self.__batch_normalization(2, 'conv5_4/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_5_x1 = self.__conv(2, name='conv5_5/x1', in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_5_x2_bn = self.__batch_normalization(2, 'conv5_5/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_5_x2 = self.__conv(2, name='conv5_5/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_5_x3_bn = self.__batch_normalization(2, 'conv5_5/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_6_x1 = self.__conv(2, name='conv5_6/x1', in_channels=208, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_6_x2_bn = self.__batch_normalization(2, 'conv5_6/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_6_x2 = self.__conv(2, name='conv5_6/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_6_x3_bn = self.__batch_normalization(2, 'conv5_6/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_7_x1 = self.__conv(2, name='conv5_7/x1', in_channels=224, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_7_x2_bn = self.__batch_normalization(2, 'conv5_7/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_7_x2 = self.__conv(2, name='conv5_7/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_7_x3_bn = self.__batch_normalization(2, 'conv5_7/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_8_x1 = self.__conv(2, name='conv5_8/x1', in_channels=240, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_8_x2_bn = self.__batch_normalization(2, 'conv5_8/x2/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.01)
        self.conv5_8_x2 = self.__conv(2, name='conv5_8/x2', in_channels=64, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_8_x3_bn = self.__batch_normalization(2, 'conv5_8/x3/bn', num_features=16, eps=9.999999747378752e-06, momentum=0.01)
        self.fc6_l2_1 = self.__dense(name = 'fc6_l2_1', in_features = 256, out_features = self.num_classes, bias = False)

    def forward(self, x):
        conv1_pad       = F.pad(x, (1, 1, 1, 1))
        conv1           = self.conv1(conv1_pad)
        conv1_bn        = self.conv1_bn(conv1)
        relu1           = F.relu(conv1_bn)
        pool1_pad       = F.pad(relu1, (0, 1, 0, 1), value=float('-inf'))
        pool1           = F.max_pool2d(pool1_pad, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)
        conv2_1_x1      = self.conv2_1_x1(pool1)
        conv2_1_x2_bn   = self.conv2_1_x2_bn(conv2_1_x1)
        relu2_1_x2      = F.relu(conv2_1_x2_bn)
        conv2_1_x2_pad  = F.pad(relu2_1_x2, (1, 1, 1, 1))
        conv2_1_x2      = self.conv2_1_x2(conv2_1_x2_pad)
        conv2_1_x3_bn   = self.conv2_1_x3_bn(conv2_1_x2)
        relu2_1_x3      = F.relu(conv2_1_x3_bn)
        concat_2_1      = torch.cat((pool1, relu2_1_x3), 1)
        conv2_2_x1      = self.conv2_2_x1(concat_2_1)
        conv2_2_x2_bn   = self.conv2_2_x2_bn(conv2_2_x1)
        relu2_2_x2      = F.relu(conv2_2_x2_bn)
        conv2_2_x2_pad  = F.pad(relu2_2_x2, (1, 1, 1, 1))
        conv2_2_x2      = self.conv2_2_x2(conv2_2_x2_pad)
        conv2_2_x3_bn   = self.conv2_2_x3_bn(conv2_2_x2)
        relu2_2_x3      = F.relu(conv2_2_x3_bn)
        concat_2_2      = torch.cat((concat_2_1, relu2_2_x3), 1)
        conv2_3_x1      = self.conv2_3_x1(concat_2_2)
        conv2_3_x2_bn   = self.conv2_3_x2_bn(conv2_3_x1)
        relu2_3_x2      = F.relu(conv2_3_x2_bn)
        conv2_3_x2_pad  = F.pad(relu2_3_x2, (1, 1, 1, 1))
        conv2_3_x2      = self.conv2_3_x2(conv2_3_x2_pad)
        conv2_3_x3_bn   = self.conv2_3_x3_bn(conv2_3_x2)
        relu2_3_x3      = F.relu(conv2_3_x3_bn)
        concat_2_3      = torch.cat((concat_2_2, relu2_3_x3), 1)
        conv2_4_x1      = self.conv2_4_x1(concat_2_3)
        conv2_4_x2_bn   = self.conv2_4_x2_bn(conv2_4_x1)
        relu2_4_x2      = F.relu(conv2_4_x2_bn)
        conv2_4_x2_pad  = F.pad(relu2_4_x2, (1, 1, 1, 1))
        conv2_4_x2      = self.conv2_4_x2(conv2_4_x2_pad)
        conv2_4_x3_bn   = self.conv2_4_x3_bn(conv2_4_x2)
        relu2_4_x3      = F.relu(conv2_4_x3_bn)
        concat_2_4      = torch.cat((concat_2_3, relu2_4_x3), 1)
        conv2_5_x1      = self.conv2_5_x1(concat_2_4)
        conv2_5_x2_bn   = self.conv2_5_x2_bn(conv2_5_x1)
        relu2_5_x2      = F.relu(conv2_5_x2_bn)
        conv2_5_x2_pad  = F.pad(relu2_5_x2, (1, 1, 1, 1))
        conv2_5_x2      = self.conv2_5_x2(conv2_5_x2_pad)
        conv2_5_x3_bn   = self.conv2_5_x3_bn(conv2_5_x2)
        relu2_5_x3      = F.relu(conv2_5_x3_bn)
        concat_2_5      = torch.cat((concat_2_4, relu2_5_x3), 1)
        conv2_6_x1      = self.conv2_6_x1(concat_2_5)
        conv2_6_x2_bn   = self.conv2_6_x2_bn(conv2_6_x1)
        relu2_6_x2      = F.relu(conv2_6_x2_bn)
        conv2_6_x2_pad  = F.pad(relu2_6_x2, (1, 1, 1, 1))
        conv2_6_x2      = self.conv2_6_x2(conv2_6_x2_pad)
        conv2_6_x3_bn   = self.conv2_6_x3_bn(conv2_6_x2)
        relu2_6_x3      = F.relu(conv2_6_x3_bn)
        concat_2_6      = torch.cat((concat_2_5, relu2_6_x3), 1)
        pool2_pad       = F.pad(concat_2_6, (0, 1, 0, 1), value=float('-inf'))
        pool2           = F.max_pool2d(pool2_pad, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)
        conv3_1_x1      = self.conv3_1_x1(pool2)
        conv3_1_x2_bn   = self.conv3_1_x2_bn(conv3_1_x1)
        relu3_1_x2      = F.relu(conv3_1_x2_bn)
        conv3_1_x2_pad  = F.pad(relu3_1_x2, (1, 1, 1, 1))
        conv3_1_x2      = self.conv3_1_x2(conv3_1_x2_pad)
        conv3_1_x3_bn   = self.conv3_1_x3_bn(conv3_1_x2)
        relu3_1_x3      = F.relu(conv3_1_x3_bn)
        concat_3_1      = torch.cat((pool2, relu3_1_x3), 1)
        conv3_2_x1      = self.conv3_2_x1(concat_3_1)
        conv3_2_x2_bn   = self.conv3_2_x2_bn(conv3_2_x1)
        relu3_2_x2      = F.relu(conv3_2_x2_bn)
        conv3_2_x2_pad  = F.pad(relu3_2_x2, (1, 1, 1, 1))
        conv3_2_x2      = self.conv3_2_x2(conv3_2_x2_pad)
        conv3_2_x3_bn   = self.conv3_2_x3_bn(conv3_2_x2)
        relu3_2_x3      = F.relu(conv3_2_x3_bn)
        concat_3_2      = torch.cat((concat_3_1, relu3_2_x3), 1)
        conv3_3_x1      = self.conv3_3_x1(concat_3_2)
        conv3_3_x2_bn   = self.conv3_3_x2_bn(conv3_3_x1)
        relu3_3_x2      = F.relu(conv3_3_x2_bn)
        conv3_3_x2_pad  = F.pad(relu3_3_x2, (1, 1, 1, 1))
        conv3_3_x2      = self.conv3_3_x2(conv3_3_x2_pad)
        conv3_3_x3_bn   = self.conv3_3_x3_bn(conv3_3_x2)
        relu3_3_x3      = F.relu(conv3_3_x3_bn)
        concat_3_3      = torch.cat((concat_3_2, relu3_3_x3), 1)
        conv3_4_x1      = self.conv3_4_x1(concat_3_3)
        conv3_4_x2_bn   = self.conv3_4_x2_bn(conv3_4_x1)
        relu3_4_x2      = F.relu(conv3_4_x2_bn)
        conv3_4_x2_pad  = F.pad(relu3_4_x2, (1, 1, 1, 1))
        conv3_4_x2      = self.conv3_4_x2(conv3_4_x2_pad)
        conv3_4_x3_bn   = self.conv3_4_x3_bn(conv3_4_x2)
        relu3_4_x3      = F.relu(conv3_4_x3_bn)
        concat_3_4      = torch.cat((concat_3_3, relu3_4_x3), 1)
        conv3_5_x1      = self.conv3_5_x1(concat_3_4)
        conv3_5_x2_bn   = self.conv3_5_x2_bn(conv3_5_x1)
        relu3_5_x2      = F.relu(conv3_5_x2_bn)
        conv3_5_x2_pad  = F.pad(relu3_5_x2, (1, 1, 1, 1))
        conv3_5_x2      = self.conv3_5_x2(conv3_5_x2_pad)
        conv3_5_x3_bn   = self.conv3_5_x3_bn(conv3_5_x2)
        relu3_5_x3      = F.relu(conv3_5_x3_bn)
        concat_3_5      = torch.cat((concat_3_4, relu3_5_x3), 1)
        conv3_6_x1      = self.conv3_6_x1(concat_3_5)
        conv3_6_x2_bn   = self.conv3_6_x2_bn(conv3_6_x1)
        relu3_6_x2      = F.relu(conv3_6_x2_bn)
        conv3_6_x2_pad  = F.pad(relu3_6_x2, (1, 1, 1, 1))
        conv3_6_x2      = self.conv3_6_x2(conv3_6_x2_pad)
        conv3_6_x3_bn   = self.conv3_6_x3_bn(conv3_6_x2)
        relu3_6_x3      = F.relu(conv3_6_x3_bn)
        concat_3_6      = torch.cat((concat_3_5, relu3_6_x3), 1)
        conv3_7_x1      = self.conv3_7_x1(concat_3_6)
        conv3_7_x2_bn   = self.conv3_7_x2_bn(conv3_7_x1)
        relu3_7_x2      = F.relu(conv3_7_x2_bn)
        conv3_7_x2_pad  = F.pad(relu3_7_x2, (1, 1, 1, 1))
        conv3_7_x2      = self.conv3_7_x2(conv3_7_x2_pad)
        conv3_7_x3_bn   = self.conv3_7_x3_bn(conv3_7_x2)
        relu3_7_x3      = F.relu(conv3_7_x3_bn)
        concat_3_7      = torch.cat((concat_3_6, relu3_7_x3), 1)
        conv3_8_x1      = self.conv3_8_x1(concat_3_7)
        conv3_8_x2_bn   = self.conv3_8_x2_bn(conv3_8_x1)
        relu3_8_x2      = F.relu(conv3_8_x2_bn)
        conv3_8_x2_pad  = F.pad(relu3_8_x2, (1, 1, 1, 1))
        conv3_8_x2      = self.conv3_8_x2(conv3_8_x2_pad)
        conv3_8_x3_bn   = self.conv3_8_x3_bn(conv3_8_x2)
        relu3_8_x3      = F.relu(conv3_8_x3_bn)
        concat_3_8      = torch.cat((concat_3_7, relu3_8_x3), 1)
        conv3_blk       = self.conv3_blk(concat_3_8)
        conv3_blk_bn    = self.conv3_blk_bn(conv3_blk)
        conv3_blk_bn_re = F.relu(conv3_blk_bn)
        pool3           = F.avg_pool2d(conv3_blk_bn_re, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=True, count_include_pad=False)
        conv4_1_x1      = self.conv4_1_x1(pool3)
        conv4_1_x2_bn   = self.conv4_1_x2_bn(conv4_1_x1)
        relu4_1_x2      = F.relu(conv4_1_x2_bn)
        conv4_1_x2_pad  = F.pad(relu4_1_x2, (1, 1, 1, 1))
        conv4_1_x2      = self.conv4_1_x2(conv4_1_x2_pad)
        conv4_1_x3_bn   = self.conv4_1_x3_bn(conv4_1_x2)
        relu4_1_x3      = F.relu(conv4_1_x3_bn)
        concat_4_1      = torch.cat((pool3, relu4_1_x3), 1)
        conv4_2_x1      = self.conv4_2_x1(concat_4_1)
        conv4_2_x2_bn   = self.conv4_2_x2_bn(conv4_2_x1)
        relu4_2_x2      = F.relu(conv4_2_x2_bn)
        conv4_2_x2_pad  = F.pad(relu4_2_x2, (1, 1, 1, 1))
        conv4_2_x2      = self.conv4_2_x2(conv4_2_x2_pad)
        conv4_2_x3_bn   = self.conv4_2_x3_bn(conv4_2_x2)
        relu4_2_x3      = F.relu(conv4_2_x3_bn)
        concat_4_2      = torch.cat((concat_4_1, relu4_2_x3), 1)
        conv4_3_x1      = self.conv4_3_x1(concat_4_2)
        conv4_3_x2_bn   = self.conv4_3_x2_bn(conv4_3_x1)
        relu4_3_x2      = F.relu(conv4_3_x2_bn)
        conv4_3_x2_pad  = F.pad(relu4_3_x2, (1, 1, 1, 1))
        conv4_3_x2      = self.conv4_3_x2(conv4_3_x2_pad)
        conv4_3_x3_bn   = self.conv4_3_x3_bn(conv4_3_x2)
        relu4_3_x3      = F.relu(conv4_3_x3_bn)
        concat_4_3      = torch.cat((concat_4_2, relu4_3_x3), 1)
        conv4_4_x1      = self.conv4_4_x1(concat_4_3)
        conv4_4_x2_bn   = self.conv4_4_x2_bn(conv4_4_x1)
        relu4_4_x2      = F.relu(conv4_4_x2_bn)
        conv4_4_x2_pad  = F.pad(relu4_4_x2, (1, 1, 1, 1))
        conv4_4_x2      = self.conv4_4_x2(conv4_4_x2_pad)
        conv4_4_x3_bn   = self.conv4_4_x3_bn(conv4_4_x2)
        relu4_4_x3      = F.relu(conv4_4_x3_bn)
        concat_4_4      = torch.cat((concat_4_3, relu4_4_x3), 1)
        conv4_5_x1      = self.conv4_5_x1(concat_4_4)
        conv4_5_x2_bn   = self.conv4_5_x2_bn(conv4_5_x1)
        relu4_5_x2      = F.relu(conv4_5_x2_bn)
        conv4_5_x2_pad  = F.pad(relu4_5_x2, (1, 1, 1, 1))
        conv4_5_x2      = self.conv4_5_x2(conv4_5_x2_pad)
        conv4_5_x3_bn   = self.conv4_5_x3_bn(conv4_5_x2)
        relu4_5_x3      = F.relu(conv4_5_x3_bn)
        concat_4_5      = torch.cat((concat_4_4, relu4_5_x3), 1)
        conv4_6_x1      = self.conv4_6_x1(concat_4_5)
        conv4_6_x2_bn   = self.conv4_6_x2_bn(conv4_6_x1)
        relu4_6_x2      = F.relu(conv4_6_x2_bn)
        conv4_6_x2_pad  = F.pad(relu4_6_x2, (1, 1, 1, 1))
        conv4_6_x2      = self.conv4_6_x2(conv4_6_x2_pad)
        conv4_6_x3_bn   = self.conv4_6_x3_bn(conv4_6_x2)
        relu4_6_x3      = F.relu(conv4_6_x3_bn)
        concat_4_6      = torch.cat((concat_4_5, relu4_6_x3), 1)
        conv4_7_x1      = self.conv4_7_x1(concat_4_6)
        conv4_7_x2_bn   = self.conv4_7_x2_bn(conv4_7_x1)
        relu4_7_x2      = F.relu(conv4_7_x2_bn)
        conv4_7_x2_pad  = F.pad(relu4_7_x2, (1, 1, 1, 1))
        conv4_7_x2      = self.conv4_7_x2(conv4_7_x2_pad)
        conv4_7_x3_bn   = self.conv4_7_x3_bn(conv4_7_x2)
        relu4_7_x3      = F.relu(conv4_7_x3_bn)
        concat_4_7      = torch.cat((concat_4_6, relu4_7_x3), 1)
        conv4_8_x1      = self.conv4_8_x1(concat_4_7)
        conv4_8_x2_bn   = self.conv4_8_x2_bn(conv4_8_x1)
        relu4_8_x2      = F.relu(conv4_8_x2_bn)
        conv4_8_x2_pad  = F.pad(relu4_8_x2, (1, 1, 1, 1))
        conv4_8_x2      = self.conv4_8_x2(conv4_8_x2_pad)
        conv4_8_x3_bn   = self.conv4_8_x3_bn(conv4_8_x2)
        relu4_8_x3      = F.relu(conv4_8_x3_bn)
        concat_4_8      = torch.cat((concat_4_7, relu4_8_x3), 1)
        conv4_blk       = self.conv4_blk(concat_4_8)
        conv4_blk_bn    = self.conv4_blk_bn(conv4_blk)
        conv4_blk_bn_re = F.relu(conv4_blk_bn)
        pool4           = F.avg_pool2d(conv4_blk_bn_re, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=True, count_include_pad=False)
        conv5_1_x1      = self.conv5_1_x1(pool4)
        conv5_1_x2_bn   = self.conv5_1_x2_bn(conv5_1_x1)
        relu5_1_x2      = F.relu(conv5_1_x2_bn)
        conv5_1_x2_pad  = F.pad(relu5_1_x2, (1, 1, 1, 1))
        conv5_1_x2      = self.conv5_1_x2(conv5_1_x2_pad)
        conv5_1_x3_bn   = self.conv5_1_x3_bn(conv5_1_x2)
        relu5_1_x3      = F.relu(conv5_1_x3_bn)
        concat_5_1      = torch.cat((pool4, relu5_1_x3), 1)
        conv5_2_x1      = self.conv5_2_x1(concat_5_1)
        conv5_2_x2_bn   = self.conv5_2_x2_bn(conv5_2_x1)
        relu5_2_x2      = F.relu(conv5_2_x2_bn)
        conv5_2_x2_pad  = F.pad(relu5_2_x2, (1, 1, 1, 1))
        conv5_2_x2      = self.conv5_2_x2(conv5_2_x2_pad)
        conv5_2_x3_bn   = self.conv5_2_x3_bn(conv5_2_x2)
        relu5_2_x3      = F.relu(conv5_2_x3_bn)
        concat_5_2      = torch.cat((concat_5_1, relu5_2_x3), 1)
        conv5_3_x1      = self.conv5_3_x1(concat_5_2)
        conv5_3_x2_bn   = self.conv5_3_x2_bn(conv5_3_x1)
        relu5_3_x2      = F.relu(conv5_3_x2_bn)
        conv5_3_x2_pad  = F.pad(relu5_3_x2, (1, 1, 1, 1))
        conv5_3_x2      = self.conv5_3_x2(conv5_3_x2_pad)
        conv5_3_x3_bn   = self.conv5_3_x3_bn(conv5_3_x2)
        relu5_3_x3      = F.relu(conv5_3_x3_bn)
        concat_5_3      = torch.cat((concat_5_2, relu5_3_x3), 1)
        conv5_4_x1      = self.conv5_4_x1(concat_5_3)
        conv5_4_x2_bn   = self.conv5_4_x2_bn(conv5_4_x1)
        relu5_4_x2      = F.relu(conv5_4_x2_bn)
        conv5_4_x2_pad  = F.pad(relu5_4_x2, (1, 1, 1, 1))
        conv5_4_x2      = self.conv5_4_x2(conv5_4_x2_pad)
        conv5_4_x3_bn   = self.conv5_4_x3_bn(conv5_4_x2)
        relu5_4_x3      = F.relu(conv5_4_x3_bn)
        concat_5_4      = torch.cat((concat_5_3, relu5_4_x3), 1)
        conv5_5_x1      = self.conv5_5_x1(concat_5_4)
        conv5_5_x2_bn   = self.conv5_5_x2_bn(conv5_5_x1)
        relu5_5_x2      = F.relu(conv5_5_x2_bn)
        conv5_5_x2_pad  = F.pad(relu5_5_x2, (1, 1, 1, 1))
        conv5_5_x2      = self.conv5_5_x2(conv5_5_x2_pad)
        conv5_5_x3_bn   = self.conv5_5_x3_bn(conv5_5_x2)
        relu5_5_x3      = F.relu(conv5_5_x3_bn)
        concat_5_5      = torch.cat((concat_5_4, relu5_5_x3), 1)
        conv5_6_x1      = self.conv5_6_x1(concat_5_5)
        conv5_6_x2_bn   = self.conv5_6_x2_bn(conv5_6_x1)
        relu5_6_x2      = F.relu(conv5_6_x2_bn)
        conv5_6_x2_pad  = F.pad(relu5_6_x2, (1, 1, 1, 1))
        conv5_6_x2      = self.conv5_6_x2(conv5_6_x2_pad)
        conv5_6_x3_bn   = self.conv5_6_x3_bn(conv5_6_x2)
        relu5_6_x3      = F.relu(conv5_6_x3_bn)
        concat_5_6      = torch.cat((concat_5_5, relu5_6_x3), 1)
        conv5_7_x1      = self.conv5_7_x1(concat_5_6)
        conv5_7_x2_bn   = self.conv5_7_x2_bn(conv5_7_x1)
        relu5_7_x2      = F.relu(conv5_7_x2_bn)
        conv5_7_x2_pad  = F.pad(relu5_7_x2, (1, 1, 1, 1))
        conv5_7_x2      = self.conv5_7_x2(conv5_7_x2_pad)
        conv5_7_x3_bn   = self.conv5_7_x3_bn(conv5_7_x2)
        relu5_7_x3      = F.relu(conv5_7_x3_bn)
        concat_5_7      = torch.cat((concat_5_6, relu5_7_x3), 1)
        conv5_8_x1      = self.conv5_8_x1(concat_5_7)
        conv5_8_x2_bn   = self.conv5_8_x2_bn(conv5_8_x1)
        relu5_8_x2      = F.relu(conv5_8_x2_bn)
        conv5_8_x2_pad  = F.pad(relu5_8_x2, (1, 1, 1, 1))
        conv5_8_x2      = self.conv5_8_x2(conv5_8_x2_pad)
        conv5_8_x3_bn   = self.conv5_8_x3_bn(conv5_8_x2)
        relu5_8_x3      = F.relu(conv5_8_x3_bn)
        concat_5_8      = torch.cat((concat_5_7, relu5_8_x3), 1)
        pool5           = F.avg_pool2d(concat_5_8, kernel_size=(8, 8), stride=(1, 1), padding=0, ceil_mode=False, count_include_pad=False)
        fc6_l2_0        = pool5.view(pool5.size(0), -1)
        #f_norm          = F.normalize(fc6_l2_0)
        #fc6_l2_1        = self.fc6_l2_1(f_norm)   
        drop_fc6        = F.dropout(fc6_l2_0,p=0.3)
        fc6_l2_1        = self.fc6_l2_1(drop_fc6)
        #fc6_l2_1        = self.fc6_l2_1(fc6_l2_0)
        return fc6_l2_1
        #return conv4_blk_bn, concat_5_8, fc6_l2_0, fc6_l2_1


    @staticmethod
    def __conv(dim, name, **kwargs):
        if   dim == 1:  layer = nn.Conv1d(**kwargs)
        elif dim == 2:  layer = nn.Conv2d(**kwargs)
        elif dim == 3:  layer = nn.Conv3d(**kwargs)
        else:           raise NotImplementedError()

        return layer

    @staticmethod
    def __batch_normalization(dim, name, **kwargs):
        if   dim == 0 or dim == 1:  layer = nn.BatchNorm1d(**kwargs)
        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)
        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)
        else:           raise NotImplementedError()

        return layer

    @staticmethod
    def __dense(name, **kwargs):
        layer = nn.Linear(**kwargs)
        return layer
